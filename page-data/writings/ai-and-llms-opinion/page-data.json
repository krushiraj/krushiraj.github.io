{"componentChunkName":"component---src-templates-blog-post-template-js","path":"/writings/ai-and-llms-opinion/","result":{"data":{"mdx":{"id":"a37f6309-3967-51ed-8b33-fe0855894145","parent":{"sourceInstanceName":"content"},"excerpt":"AI and LLMs - What do you need to know? Intro We see a boom in usage of AI, LLMs and chatbots in recent year. People have been astonishedâ€¦","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"My Opinion on AI and LLMs\",\n  \"date\": \"2024-03-17\",\n  \"type\": \"article\",\n  \"published\": true,\n  \"keywords\": \"ai,llms,jobs,prompts,training,data,programming,writing\",\n  \"description\": \"A brief opinion on what AI and LLMs are doing and how would they effect us.\",\n  \"tags\": \"ai,llms,programming,writing\",\n  \"banner\": \"./ai-and-llms.png\",\n  \"bannercaption\": \"Image generated by LLM\",\n  \"technologies\": \"ai,llm\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"AI and LLMs - What do you need to know?\"), mdx(\"h2\", null, \"Intro\"), mdx(\"p\", null, \"We see a boom in usage of AI, LLMs and chatbots in recent year. People have been astonished with the results that we are seeing from these, this is surely a disruptive tech. But, we all have the same question, \\u201CHow far can the AI go?\\u201C.\"), mdx(\"p\", null, \"We have a vast area of expectations where AI can go, what AI can achieve and what it can do. Let\\u2019s not get into predictions zone now. We will look at what AI can do now and how will it effect us.\"), mdx(\"h2\", null, \"What can AI do now (not in future)?\"), mdx(\"p\", null, \"In principle every AI that we had till pre-LLM era was a niche AI i.e., we had an AI specifically for playing chess or cards based games, we had AI just to run a car or drone, we had AI to detect anamolies in the images, we had AI to do something very fast when compared to a average human in a specific field. But with the introduction of LLMs we are seeing buzz around AI being able to do almost everything. People are claiming that AI is like a super-human that can do almost everything for you. Be it in the writing copies or code, reading large texts, generating images, videos and a lot more to mention.\"), mdx(\"p\", null, \"So, does this mean it can do anything? People always had this question of \\u201CWill AI replace us?\\u201C. It wasn\\u2019t just a threat for a single field or profession it was considered a threat for almost every field and every profession out there. Because, why not, now it can write marketing posts, blogs, read enormous content and summarise in no time when compared to humans, generate images, video and audio in just few seconds, can write code to build applications. It is natural to think that we might get replaced by the AI in the near future.\"), mdx(\"h2\", null, \"Will AI replace us?\"), mdx(\"p\", null, \"I would like to start this with a famous quote (allegedly by Elon Musk, I couldn\\u2019t find the reference video or tweet for this) that says, \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u201CAI won\\u2019t replace you but the person using AI will!\\u201D\"), \".\"), mdx(\"p\", null, \"What did he mean by that? Will AI not replace us? Are we still pioneers in the game?\"), mdx(\"p\", null, \"To understand that we must have a basic understanding of how current AI tools work and how LLMs work at the fundamental level. (if you want to dig deep on this top, \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/\"\n  }, \"What Is ChatGPT Doing \\u2026 and Why Does It Work?\"), \" is a good article). In simple terms LLMs are being trained by lots and lots and lots of data, from this data it builds a probabilistic next possibilities when it sees a series of words. It guesses one word at a time, with good probablity. As it is trained on a very large data, it seems to be guessing right words in the series.\"), mdx(\"p\", null, \"Let me give you an example or an analogy. We all learnt our mother tongue without proper learning of grammar or vocabulary for that language. How was this possible without formal education on that language? It was because we have been listening to it for a very long time and we have been habituated with the patterns and we just make guesses with some high probability (so we have been fed with large amounts of data and our brain does a guess work). In theory the same thing is happening with the LLMs.\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/rahulkarda/bionic-reader\"\n  }, \"Bionic Reading\"), \" is another example to show that we think just like what LLMs do now. We try to predict the next word. I know, I know you might argue that how is it same or that both are completely different. Just take this analogy. When you open the link for bionic reading above you have 2 paragraphs, while reading your brain constantly tries to predict the next word, by making emphasis on just parts of the words it increases the prediction confidence for most of the words and you try to predict faster hence read faster. Also bionic reading doesn\\u2019t work well if you don\\u2019t know the words, or if you are seeing the words for the first time. Which means your brain was never trained on that new data and it couldn\\u2019t predict it. Same would be the case with LLM, it needs to data to do something.\"), mdx(\"p\", null, \"With this, one must realise that it can only create from what has been fed to it. It \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"still\"), \" doesn\\u2019t have the ability to create something completely new on its own. So if you\\u2019re thinking that it can create anything better than humans, you\\u2019re wrong, because it only can work on the data it has been trained with, nothing new will be created.\"), mdx(\"h2\", null, \"How can one make use of AI?\"), mdx(\"p\", null, \"Now that you\\u2019ve known that AI/LLMs you see these days are basically some program that has access to large amounts of data. With that you can take it to advantange that you have access to such enormous data at your fingertips.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Consider it as someone who has access to large data to lookup before writing something\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It can be an intern for your work (I will tell why I called it intern)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It can be a pair programmer that has access to a lot of already written code, algorithm patterns and docs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It can be an assitant to get tedious tasks done based on the existing data/work\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Any role that can be performed with the work that has already been done to do the same again or in a similar way\")), mdx(\"h3\", null, \"Some examples of where it would work and where it wouldn\\u2019t:\"), mdx(\"h4\", null, \"AI as a developer\"), mdx(\"p\", null, \"If you want to create a new app with the help of LLM. If you ask it directly to build an app for you with a feature list given. It will give you some basic setup with some mediocre code. But if ask specifics about it, then the AI will give you better answers but not all the code. Now trying asking even more specific about a minute problem. Use the proper vocabulary and proper jargons, now you will see the answers which feels like it is coming from an expert. An example for this would be the following, I want it to write a smart contract for me\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Ask it write a code to create an NFT smart contract where it distributes another ERC20 as dividend\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You won\\u2019t really get code for this, as the data it got trained would probably not have enough data for this\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Now ask it for a code to create and NFT with ERC721, 721 Enumerable standards, also an ERC20 abstract factory usage, where it can accept ERC20 tokens for exchange of NFTs, then distribute the tokens to all holders\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You would now get a better code but not completely working\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Now ask it for a smart contract class where we keep track of all the holdings of NFT and ERC20 tokens. Then use a function to calculate all the distributions, a function that calls send function in ERC20 to distribute the tokens. Use proper storage and memory on the blockchain to store the holdings and distribution data.\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Now you will get some really good code, you might have to still work on it\")))), mdx(\"p\", null, \"The reason why people feel like AI is working is that the queries they are asking are from pre-trained data. Whatever the code you get from code related AIs like GitHub or Open-Interpreter or Devin, it is all based on the existing code base. The reason why it wouldn\\u2019t work better with writing smart contracts is that it is fairly new topic with not much data for training on this when compared other areas in development. This would also be the same case if you want to take help of LLM to design a new ML model. Unless you use proper vocabulary and ask pin pointed questions all you hear from it is to use a Neural network or basic regression model.\"), mdx(\"h4\", null, \"AI as a writer\"), mdx(\"p\", null, \"Consider you are writer who write blogs, books, news articles, copies for marketing. You want the AI to do your job. Now lets take a contemporary event, say current of Gold price soaring and you want it write an article about it.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Ask it directly to write a news article about the soaring gold prices in the current month.\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It will give you a news article but it might not have a proper structure and it won\\u2019t give out really any good information\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Now ask it to go through previous events when the gold prices were up and compare those events with current day and ask it for an analysis on that. Also mention to have a proper template followed by most news article writers\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Now you will see some good structured information and stats that could help the readers\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Now tell it about your view, ask it to rewrite in the tone of your choice. Ask it pull up the historical data and also cite all the references from previous news articles. Ask it pull some data points like GDP, Per capita income, inflation, gold reserves, currency strength, political events etc., and then do some proper analytics on the data points and deduce the insights.\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It will now give you one of the best article with all the data properly used with a proper structure which is almost ready for publishing.\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"The key takeaway is that you must have minimum knowledge about what you ask, use proper vocabulary so the guessing works with correct phrases on LLM. More the data and specifics you mention better the quality of the answers because of better picking of next words in the series of words it generates.\")), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"strong\", {\n    parentName: \"em\"\n  }, \"LLMs are just autocomplete on steroids\"), \" - Linus Torvalds\"), \" (reference \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://youtu.be/VHHT6W-N0ak\"\n  }, \"https://youtu.be/VHHT6W-N0ak\"), \")\"), mdx(\"h2\", null, \"Endnote\"), mdx(\"p\", null, \"AI is not some silver bullet to tackle all things. It is just a new tool which better at doing things. Make use of it to boost productivity, for example a piece of code that you\\u2019d write in 1hr, with the help of AI/LLMs you can get it done within 20mins or so. Get the basics right, put LLMs into work to make your work faster. It will boost your research speed by 10 folds. It will help you comprehend large texts without losing important information. So think of AI as an assistant that does the heavy lifting for you when you instruct them in the proper direction and help you all along.\"), mdx(\"p\", null, \"We also made an episode on how AI and LLMs are being used and can be used, you can listen to it \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://mediocreminds.vercel.app/ai-and-llms-1\"\n  }, \"here\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"My Opinion on AI and LLMs","date":"March 17, 2024","description":"A brief opinion on what AI and LLMs are doing and how would they effect us.","technologies":"ai,llm","tags":"ai,llms,programming,writing","keywords":"ai,llms,jobs,prompts,training,data,programming,writing","banner":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='400'%20viewBox='0%200%20400%20400'%20preserveAspectRatio='none'%3e%3cpath%20d='M234%2052c-1%201-1%201%201%201%203%200%205%204%204%205l-8%205c-1-1-1%202-1%207v7l2-2c3-2%2015-6%2016-5l2%203c0%203%200%203%202%202l6-1c2%201%203%200%203-1l2-3c2-2%202-2-1-2s-3%200-1-1c2-2%202-2-4-4l-9-4-4-2c0-2-5-7-7-7l-3%202m-66%204-1%204-1%203c-2-1-2%200-2%204l-1%205c-1%200-1%201%201%201%203%202%206%205%2010%2011%201%203%203%205%204%205l1%201%205%2011c4%209%204%2010%203%2014l-1%2015c0%2010%200%2011%202%2012%202%200%203%204%200%204l-2%203-3%203v1c1%201%201%201%2010-8%206-7%207-8%207-12v-4l4%201h4v21l4-5%204-5%203-6%202-11c0-7-1-9-5-9l-4-3-2-2-1-1h-1l-5%201c-3-1-3-1-3-7%200-15-7-19-7-4l-1%204V86c0-20%201-19-7-17-4%201-4%201-4-2s0-3-1-1l-2%202-3-2c0-2%200-2-1%200-1%201-1%201-1-2l-2-3-2-4-1-1m55%2010c-1%207-2%208-5%206-1-1-2-2-2-5%200-2%200-3-1-2l-1%202c0%202%200%203-2%202-3%200-3%201-3%208l-1%2017v8h3c6-2%2010-7%207-10-3-2-1-4%203-4%205%200%206-3%206-15%200-11-1-14-2-14s-2%202-2%207m-85%203c-3%202-5%206-4%208l4%201c3%200%203%200%201%202-2%201-2%202-2%206v5l4-1h14l-2-3-7-6-5-4h3l4%201v-5l-2-5c-1-2-6-1-8%201m114%2015c-3%202-4%203-3%204l1%204c0%202%201%203%203%203%203%200%203-1%203-2-1-4%200-6%203-4%204%203%206-1%202-5-4-3-4-3-9%200m-134%200c-2%201-2%203-2%208%200%208%201%2010%203%2010%202%201%203%200%204-4%202-4%202-5%204-4l2%203%204%201c4%200%204%200%202-6-1-7-5-8-5-2%200%202-1%202-3%202s-3%200-3-2l-2-4c-2-3-3-3-4-2m161%203c-3%202-3%202-2%205l1%206c1%203%202%204%207%204h4l-1-6c0-5-1-7-3-9-3-4-3-4-6%200m-133%205-1%201-2%201c0%203-2%207-4%207-3%200-3%204-2%2013%200%208%201%208%202%208%202%200%202%200%202%203-2%208-3%208%202%208a50%2050%200%200%200%2014-1c-5%200-2-3%204-3l7-2c2%200%202%200%201%203l-3%203%204%202c3%200%203-7%201-10-2-2-2-3%200-3s7-5%207-8-3-9-5-10l-5-3-2-2-3%202c-2%201-3%203-3%205h-1c0-3-8%2011-8%2014s-2%203-2%201l-1-14-1-14c0-2-1-2-1-1m93%203-8%207c-6%206-7%2010-4%2012l1%202%202%206c3%205%203%2012%200%2017l-3%205%207-10%203-1%202%201%203-1%206-1h5c2%202%204%201%204-2l2-5%201-2c0-2-3-1-3%200h-1l-1-2c-4%200-2-4%201-5%205-1%209-4%208-6l-1-7c-1-7-1-7-4-7-2-1-2-1-1%205%200%207%200%2010-2%208l-2-4c-1-1-1%202-1%205%200%205%200%207-1%206l-1-1c1-6%200-15-1-15l-2-1c-1-1-1-1-2%201-2%203-3%202-3-2s-1-5-4-3m-139%203v3c1%205-2%2013-5%2014l-2%202%205%204%206%204c3%200%2010%208%2011%2013%201%206%201%207%205%209l4%202%201-12c0-12%200-13%202-13%203-1%205%201%203%202h-2l-1%201-1%203c0%201%200%202%203%203l3%201v-4c0-4%200-5%202-4%203%200%203-2%200-7-3-6-3-6-10-8l-10-4-7-6c-2%200-4-2-5-3h-2m185%2011a64%2064%200%200%200-14%2010l-4%201c-2%201-2%201%200%202%201%201%202%202%203%201%201%200%202%202%202%2010%200%207%201%208%202%203%201-1%201%200%201%203%200%206%201%207%205%207%203%200%206-5%208-10%200-4%205-10%208-11l10-9-7-4-7-5c0-1-2-1-7%202m-36%2030-7%207c-5%207-10%2010-18%2013l-6%203c-4%202-5%201-1-2l3-4%203-2c2-2%202-2%200-2l-6%202-4%201-1-1c-2%200-3%203-3%206s0%203%202%203c4%200%204%200-1%207-5%205-5%206-4%209s0%207-2%2013l-2%205-1-7c-1-10-1-10-7-7-2%200-2-2-2-15%200-18%200-19-4-15-3%203-3%203-1%206l3%204-3%208-4%208-4%204c-3%202-5%203-5%205%200%203%200%203-8%201h-3l2%205%201%208%202%204%201%203-5-4c-5-4-7-6-9-6l-4-2c0-2-1-3-2-3l-1-2c-1-2-1-2-4-2l-22%202c0-3%204-6%207-6s4%200%204-3c0-2%201-2%203-2l8-2c-2-1%201-3%204-3s4%202%202%203c-6%202%205%204%2016%204l7-1%203-6c6-18-2-33-18-36-3-1-3-1-3%202%200%205-5%205-5%200%200-2-1-3-4-3h-3v16l-1%202c-2%201-2%200-2-2%200-5-1-5-5-4-2%202-3%203-3%206%200%206%201%2011%202%2011h1l4%201%203%201-7-1-5-2h-1c0%202-3%201-6-1l-2-2h4l3%201%201-7%202-8%202-3c0-2-3-1-4%201l-2%202-16-1h-4c-1%202-4%201-3-2v-2l-8%2012v2c-2%201-2%201%200%203l13%2013c0%201-8-3-11-6-9-6-24-10-30-7-8%204-10%2011-6%2021l2%208c0%203%200%203%205%203s6-1%207-3c1-1%201-1%202%201%200%201%201%202%202%201v2l1%203c2%203%209%201%2017-4%205-2%205-2%2011-1%205%201%206%202%207%204l4%204c1%200%202%201%202%204l1%204h16l-1%205c0%205-1%206-2%204v-2c3-4-5-7-15-6a1538%201538%200%200%200-12%200c-1-2-1-2-5%202-4%203-5%204-9%203-8-1-13%205-15%2015a491%20491%200%200%201-1%2015l1%206c0%202%200%204-1%203h-4c-4%201-9%201-13-2-2-2-4-2-5-1-2%201-2%203%201%206%203%204%204%204%2010%204%208%200%208%201-1%204s-10%205-4%207c4%202%205%204%205%208%200%206%208-4%209-13%202-8%203-5%203%208v14l-2-1c-4%200-11%204-11%206s4%208%208%2010c6%202%2024%200%2039-6%209-3%207-6%2022%2029l4%2012h-34l-96%202c-11%201-10%201-10%205%200%205%201%206%207%207a949%20949%200%200%200%20175%2011c22%201%2031%200%2031-2l21-1c14%200%2020%200%2019-1-2-1-2-1%201-1h3l-2-4-2-6%202%202%202%204h16c17%200%2031-1%2034-3l1-1-7-2a244%20244%200%200%200-44-4l13-32c8-19%207-18%2012-18l16%204c17%205%2026%206%2032%203%203-2%203-2%201-3-10-4-10-4-10-18v-9l-5-1c-7-3-9-5-7-9s1-7-2-8c-2-1-2-1%201-1s4%200%204-2l-1-4-2-3c-1-2-1-2%202-2l4-2%203-3c2-2%203-5%201-7-2-3-13-2-12%201l-9%206-10%204%204-5%205-6-3-8c-3-9-2-8-4-8l-1%205c0%206-1%206-7%204h-8c-5%201-5%202-2%203l4%201c2%202%207%203%209%202%203-2%204%200%202%203-4%205-13%207-19%204l-4-1c-2-1-2-1%200-3%201-2%202-3%201-4l3-9%203-7h8l8%201c1%201%205-1%205-3l-2-1-5%202c-3%200-3%200-3-4%200-5%200-5-8-6l-5-1h5c5%201%207%200%208-1%202-2%204-2%206%201%201%202%201%202%202%201l-1-5c-1-2-1-2%201-4l2-2c0-2-7-1-10%201l-11%201h-9l1-2c0-4-2-4-3-1%200%202-1%202-3%202h-3l-4%201c-3%200-5%203-5%205%201%202%200%202-1%202-3%200-5%202-5%204l-2%204c-1%202-1%202%202%201%203%200%204%200%203%201l1%201v2l-9%203c0-3-3-5-4-3s-7%205-7%204l2-6%202-11c0-6%201-7%202-7l-2-1c-5-2-8-7-8-13v-6l4-1h5l3%206c2%206%203%206%207%206s5%200%207-2l3-2%205-2c4-2%208-2%207%200-2%202%202%204%206%203%203%200%203%200%203%203%200%202%201%203%204%203%205%201%206%200%203-4v-5h4v1c-2%201%200%203%205%203%204%201%205%201%206-1h5l8%203c3%202%203%202%201%203v4c5%207%209%209%205%202-4-8-1-9%207-2%204%204%205%204%205%201l1-3%201%201v2l3-1c0-2-2-2-13-5-4-1-7-3-4-3l3-2c2-1%202-1%200-3-3-2-5-7-5-9l7-3c8-2%2012-2%2021%203%208%204%2010%202%203-4-5-4-20-4-29%200l-6%202h-1c-1%202-3%201-3-1%201-1%200-2-3-3l-3-1%203-2%204-2-4-1c-3%200-3%200-2-2l2-2-4-13-1%202c3%205%203%208%201%208l-6%201-9%201-5%201-1%201-1-2c1-4-4-5-8-1-5%203-5%206-2%208%202%201%202%201%200%201h-3l-1%201-5%201c-2%201-2%201%200%202%202%202%201%202-4%203l-3%201v-16h6c5%200%206-1%206-2%201-4%201-9-1-8l-1-1c-1-2-2-2-6-1m15%2020%201%206c0%204%200%205%203%206%202%201%202%201%202-2%200-2%200-2%205-2l6%201c1%201%203%200%204-3l4-3-3-1-7%202c-6%203-8%203-12-2l-3-2M77%20175c-1%202-3%2011-2%2012h2l7-2%204-1h1l3-1-3-1-3-2c-4-5-8-6-9-5m38%2040c0%207%202%209%207%208l7%201c2%201%202%201%201-4%200-7%200-6-8-7-7%200-7%200-7%202m59%204%202%204%202%205%201%201%202%202c1%201%202%201%204-3l3-4c1-1%200-2-3-3l-4-2h-7m34%204h-4l-2%201c1%202%201%204-1%208v6l1%202%203-2c3-2%205-5%205-12%201-3-1-5-2-3m-164%204c-7%202-5%204%207%209%206%202%209%205%208%209v2l1-1%203-2c4-3%207-8%207-13s0-5-2-4H51c-2-2-2-2-7%200m192%209-2%202c3%201%200%202-5%201h-6l-5%201h-3l1%208%201%2012v3l4%203c8%204%2015%206%2016%204%202-1%200-3-3-3l-7-3-4-2v-7c0-8-1-7%2010-10l7-4h2l5%201c4%200%204%200%201-1-3%200-3%200-3-3%200-2%200-3-2-3h-4l-3%201m44%2031c0%202%201%202%203%202%204%200%204%200%205%205%201%204%201%205-2%207l-3%202%202%202a139%20139%200%200%200%2024%2011l-1-1c-6-3-16-15-18-23l-1-2%205%202%206%202%202-2c1-3%201-3-6-3-6%200-8%200-10-2l-4-2-2%202m-19%2012c-7%203-12%209-12%2013s2%207%204%207%2015-21%2014-23l-6%203m-61%2013%201%209h4c6%200%208-1%208-4s-4-4-9-3h-3v-5c0-3-1-2-1%203m18-4c-3%200-4%205-3%2017v8h-3l3%201%206%202v-9c2-21%202-20-3-19m-18%2033v19l4%201c4%200%204%200%204-3%200-2-5-18-7-19-1-1-1%200-1%202m10%2022%203%209%201%207h11l11%201c1-2-5-6-12-8s-9-3-11-7c-2-3-3-4-3-2'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1,"src":"/static/5c2ccb6f687a5e5693e05efe0173b99c/2a4de/ai-and-llms.png","srcSet":"/static/5c2ccb6f687a5e5693e05efe0173b99c/6d161/ai-and-llms.png 150w,\n/static/5c2ccb6f687a5e5693e05efe0173b99c/630fb/ai-and-llms.png 300w,\n/static/5c2ccb6f687a5e5693e05efe0173b99c/2a4de/ai-and-llms.png 600w,\n/static/5c2ccb6f687a5e5693e05efe0173b99c/db955/ai-and-llms.png 900w,\n/static/5c2ccb6f687a5e5693e05efe0173b99c/a8378/ai-and-llms.png 1024w","srcWebp":"/static/5c2ccb6f687a5e5693e05efe0173b99c/ad85c/ai-and-llms.webp","srcSetWebp":"/static/5c2ccb6f687a5e5693e05efe0173b99c/e7487/ai-and-llms.webp 150w,\n/static/5c2ccb6f687a5e5693e05efe0173b99c/403a4/ai-and-llms.webp 300w,\n/static/5c2ccb6f687a5e5693e05efe0173b99c/ad85c/ai-and-llms.webp 600w,\n/static/5c2ccb6f687a5e5693e05efe0173b99c/210c1/ai-and-llms.webp 900w,\n/static/5c2ccb6f687a5e5693e05efe0173b99c/cc834/ai-and-llms.webp 1024w","sizes":"(max-width: 600px) 100vw, 600px"}}},"bannercaption":"Image generated by LLM"},"fields":{"slug":"/writings/ai-and-llms-opinion/","timeToRead":{"minutes":9.225},"socialImage":{"childImageSharp":{"original":{"width":2400,"height":1254,"src":"/static/daabd8e131aef89a917442f84a245c89-f38d10471b46989a31ebdeb7e1ad6ec5.png"}}}}}},"pageContext":{"slug":"/writings/ai-and-llms-opinion/","previous":null,"next":{"parent":{"name":"index","sourceInstanceName":"content"},"fields":{"slug":"/writings/fixed-point-vs-abdk-math/"},"frontmatter":{"title":"FixedPointMathLib vs ABDKMath64x64 - What should you use?","published":true,"type":"article"},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"FixedPointMathLib vs ABDKMath64x64 - What should you use?\",\n  \"date\": \"2023-12-23\",\n  \"type\": \"article\",\n  \"published\": true,\n  \"keywords\": \"web3,math,arithmetic,fixedpoint,solidity\",\n  \"description\": \"An article about which library to pick for fractional arithmetic in Solidity.\",\n  \"tags\": \"web3,math,arithmetic,fixedpoint,solidity\",\n  \"banner\": \"./comparison.jpeg\",\n  \"bannercaption\": \"Image from Google Images\",\n  \"technologies\": \"solidity,web3\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"FixedPointMathLib vs ABDKMath64x64 - What should you use?\"), mdx(\"p\", null, \"In Solidity we don\\u2019t have \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Fixed Point Arithmetic\"), \" out-of-the-box, hence we rely on various libraries to make it easier and safer for us. \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/Vectorized/solady/blob/main/src/utils/FixedPointMathLib.sol\"\n  }, \"FixedPointMathLib\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/abdk-consulting/abdk-libraries-solidity/blob/master/ABDKMath64x64.sol\"\n  }, \"ABDKMath64x64\"), \" are some of the well known libraries that handle this.\"), mdx(\"p\", null, \"Lets see which one should you be using and why? There can be a lot of factor to support the decision of which one to use, we will go through a couple of things that matter and see which one has to be used based on the scenario that a smart contract developer has.\"), mdx(\"h2\", null, \"Differences\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Precision and Range\"), \":    \"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"ABDKMath64x64\"), \": Operates with a 64.64 fixed point math library, meaning it uses 64 bits for the integer part and 64 bits for the fractional part. This allows for high precision and a wide range of numbers, but it can be more computationally intensive.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"FixedPointMathLib\"), \": This library uses a different approach and have a different precision range with WAD factor which is \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"10**18\"), \".\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Performance\"), \":\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"ABDKMath64x64\"), \": Known for high precision, but this can come at the cost of gas (when used in Ethereum smart contracts), as operations are more complex and you might have to keep converting the numbers from \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"int\"), \" to \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"64x64\"), \" format.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"FixedPointMathLib\"), \": Less gas-intensive for certain operations as it relies on the Yul to make use of direct math functions mostly.\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Use Cases\"), \":    \"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"ABDKMath64x64\"), \": Its high precision makes it suitable for financial applications, complex calculations, and anywhere that a very small margin of error is critical.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"FixedPointMathLib\"), \": Good to use when we have simple calculations that can be done with in 18 decimal point precision. Most of the transactions of ERC20 and user facing data will be similar to this. So better for naive usage.\")))), mdx(\"h2\", null, \"Code in action\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-solidity\"\n  }, \"// SPDX-License-Identifier: MIT\\npragma  solidity  >=0.8.0;\\n\\nimport  \\\"https://github.com/Vectorized/solady/blob/main/src/utils/FixedPointMathLib.sol\\\";\\n\\nimport  \\\"https://github.com/abdk-consulting/abdk-libraries-solidity/blob/master/ABDKMath64x64.sol\\\";\\n\\nusing FixedPointMathLib for  uint256;\\nusing FixedPointMathLib for  int256;\\n\\nusing ABDKMath64x64 for  int128;\\n\\ncontract Math {\\n    function mul0(uint256 a,  uint256 b)  public  pure  returns  (uint256 c)  {\\n        c = a * b;\\n    }\\n    \\n    function mul1(int128 a,  int128 b)  public  pure  returns  (int128 c)  {\\n        c = a.mul(b);\\n    }\\n    \\n    function mul2(uint256 a,  uint256 b)  public  pure  returns  (uint256 c)  {\\n        int128 aFixed = ABDKMath64x64.fromUInt(a);\\n        int128 bFixed = ABDKMath64x64.fromUInt(b);\\n\\n        // Perform the calculation using ABDKMath64x64\\n        int128 rawResult = aFixed.mul(bFixed);\\n        \\n        // Convert the result back to uint for the return value\\n        c = ABDKMath64x64.toUInt(rawResult);\\n    }\\n\\n    function mul3(uint256 a,  uint256 b)  public  pure  returns  (uint256 c)  {\\n        c = a.mulWad(b);\\n    }\\n\\n    function pow0(int256 a,  int256 b)  public  pure  returns  (int256 c)  {\\n        c = a.powWad(b);\\n    }\\n\\n    function pow1(int128 a,  uint256 b)  internal  pure  returns  (int128 c)  {\\n        c = a.pow(b);\\n    }\\n}\\n\")), mdx(\"p\", null, \"This smart contract tries to make use of both the libraries to do some basic multiplication and then calculate power.\"), mdx(\"p\", null, \"Now we will try to execute each of those and see how each performs. We only care about inputs, outputs and gas here. So rest of logs are omitted here.\"), mdx(\"h3\", null, \"mul0\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"to: Math.mul0(uint256,uint256)\\n\\nexecution cost\\n1049 gas (Cost only applies when called by a contract)[]\\n\\ndecoded input\\n{ \\\"uint256 a\\\": \\\"120\\\", \\\"uint256 b\\\": \\\"130\\\" }[]\\n\\ndecoded output\\n{ \\\"0\\\": \\\"uint256: c 15600\\\" }[]\\n\")), mdx(\"p\", null, \"This is direct multiplication in solidity without any help of libraries. Simple to understand inputs and output.\"), mdx(\"h3\", null, \"mul1\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"to\\n\\nMath.mul1(int128,int128) 0x9D7f74d0C41E726EC95884E0e97Fa6129e3b5E99[]\\n\\nexecution cost\\n1058 gas (Cost only applies when called by a contract)[]\\n\\ndecoded input\\n{ \\\"int128 a\\\": \\\"120\\\", \\\"int128 b\\\": \\\"130\\\" }[]\\n\\ndecoded output\\n{ \\\"0\\\": \\\"int128: c 0\\\" }[]\\n\")), mdx(\"p\", null, \"The output here is 0. Any idea about why is that 0?\\nIt is because the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"ABDKMath64x64\"), \" library expects the number to be in the form of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"64.64\"), \" bit representation. That means we need to convert the number to binary and then add 64 bit of binary 0 to make fractional part 0 for that number. Lets do that for 120 and 130\\n| decimal | binary (without 64 zeros for fractional part) | decimal for 64.64 |\\n|----------|---------|------------------|\\n|120 | 1111000 | 2213609288845146193920 |\\n|130 | 10000010 | 2398076729582241710080 |\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"to\\n\\nMath.mul1(int128,int128) 0x9D7f74d0C41E726EC95884E0e97Fa6129e3b5E99[]\\n\\nexecution cost\\n1058 gas (Cost only applies when called by a contract)[]\\n\\ndecoded input\\n{ \\\"int128 a\\\": \\\"2213609288845146193920\\\", \\\"int128 b\\\": \\\"2398076729582241710080\\\" }[]\\n\\ndecoded output\\n{ \\\"0\\\": \\\"int128: c 287769207549869005209600\\\" }[]\\n\")), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"287769207549869005209600 = 111100111100000000000000000000000000000000000000000000000000000000000000000000 = 15600\")), mdx(\"h3\", null, \"mul2\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"Math.mul2(uint256,uint256) 0x9D7f74d0C41E726EC95884E0e97Fa6129e3b5E99[]\\n\\nexecution cost\\n1351 gas (Cost only applies when called by a contract)[]\\n\\ndecoded input\\n{ \\\"uint256 a\\\": \\\"120\\\", \\\"uint256 b\\\": \\\"130\\\" }[]\\n\\ndecoded output\\n{ \\\"0\\\": \\\"uint256: c 15600\\\" }[]\\n\")), mdx(\"p\", null, \"This is using \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"ABDKMath64x64\"), \", but the catch here is we used extra helpers to convert instead of doing it all by ourselves like we did before. Hence extra gas cost.\"), mdx(\"h3\", null, \"mul3\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"to\\n\\nMath.mul3(uint256,uint256) 0x9D7f74d0C41E726EC95884E0e97Fa6129e3b5E99[]\\n\\nexecution cost\\n877 gas (Cost only applies when called by a contract)[]\\n\\ndecoded input\\n{ \\\"uint256 a\\\": \\\"128\\\", \\\"uint256 b\\\": \\\"128\\\" }[]\\n\\ndecoded output\\n{ \\\"0\\\": \\\"uint256: c 0\\\" }[]\\n\")), mdx(\"p\", null, \"The same again, not the results we wanted to see. \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"FixedPointMathLib\"), \" expects a number with 18 decimal places i.e., we need to append 18 zeros after the number\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"to\\n\\nMath.mul3(uint256,uint256) 0x9D7f74d0C41E726EC95884E0e97Fa6129e3b5E99[]\\n\\nexecution cost\\n877 gas (Cost only applies when called by a contract)[]\\n\\n\\ndecoded input\\n{ \\\"uint256 a\\\": \\\"120000000000000000000\\\", \\\"uint256 b\\\": \\\"130000000000000000000\\\" }[]\\n\\ndecoded output\\n{ \\\"0\\\": \\\"uint256: c 15600000000000000000000\\\" }[]\\n\")), mdx(\"p\", null, \"Now we get the correct output but with 18 zeros appended to it.\"), mdx(\"h3\", null, \"pow0\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"to\\n\\nMath.pow0(int256,int256) 0x9D7f74d0C41E726EC95884E0e97Fa6129e3b5E99[]\\n\\nexecution cost\\n2723 gas (Cost only applies when called by a contract)[]\\n\\ndecoded input\\n{ \\\"int256 a\\\": \\\"2000000000000000000\\\", \\\"int256 b\\\": \\\"10000000000000000000\\\" }[]\\n\\ndecoded output\\n{ \\\"0\\\": \\\"int256: c 1023999999999999995727\\\" }[]\\n\")), mdx(\"p\", null, \"Uses the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"FixedPointMathLib\"), \". I would expect \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"2 ** 10\"), \" to be \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"1024\"), \". But the value here is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"1023.999.....5727\"), \" which is not correct but close when we round up.\"), mdx(\"h3\", null, \"pow1\"), mdx(\"p\", null, \"Users the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"ABDKMath64x64\"), \". For conversion\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"2\"), \" - \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10\"), \" in binary and when converted to int with 64 bit decimal places, it is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"18446744073709551616\"), \"\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10\"), \" - we give this directly as the power is expected in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"int128\"), \" but not \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"64.64\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"to\\n\\nMath.pow1(int128,uint256) 0xddaAd340b0f1Ef65169Ae5E41A8b10776a75482d[](https://remix.ethereum.org/#)\\n\\nexecution cost\\n\\n2302 gas (Cost only applies when called by a contract)[](https://remix.ethereum.org/#)\\n\\ninput\\n\\n0x9ea...0000a[](https://remix.ethereum.org/#)\\n\\ndecoded input\\n\\n{ \\\"int128 a\\\": \\\"36893488147419103232\\\", \\\"uint256 b\\\": \\\"10\\\" }[](https://remix.ethereum.org/#)\\n\\ndecoded output\\n\\n{ \\\"0\\\": \\\"int128: c 18889465931478580854784\\\" }[](https://remix.ethereum.org/#)\\n\")), mdx(\"p\", null, \"The output when converted to binary will give us \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10000000000+64 zeros\"), \". Those 64 zeros can be omitted to get the integral part which then converts to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"1024\"), \", the exact output for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"2 ** 10\")), mdx(\"h3\", null, \"Gas costs\"), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": null\n  }), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"ABDKMath64x64\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"FixedPointMathLib\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"mul\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"1058\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"877\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"pow\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"2302\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"2723\")))), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"If we include gas to convert for \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"ABDKMath64x64\"), \" it would add around 300\")), mdx(\"h2\", null, \"Conclusion\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"ABDKMath64x64\"), \" is gas efficient for complex calculations and very precise and accurate for smaller integral numbers with large fractional part.\\n\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"FixedPointMathLib\"), \" is good with large numbers and has less precision for more complex calculations, but highly gas efficient for basic math.\"), mdx(\"p\", null, \"So, if you are building something that include complex formulae like bonding curve, exponential farming or anything that requires high precision and complex calculations one should go for \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ABDKMath64x64\"), \", else if you require basic math with low precision which is mostly used in transfer, ERC20 related, more user facing applications and functions one should go for \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"FixedPointMathLib\"), \", as for user facing you don\\u2019t have to put in extra effort to convert it to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"64.64\"), \"format when compared to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"WAD\"), \".\"));\n}\n;\nMDXContent.isMDXComponent = true;"}}},"staticQueryHashes":["3572198028","3765610985"]}