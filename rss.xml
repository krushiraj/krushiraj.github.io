<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Krushi Raj Tula - RSS Feed]]></title><description><![CDATA[Portfolio of Krushi Raj Tula. A developer, geek, enthusiast, who loves to solve problems and fix things with technology. You can read my writings here.]]></description><link>https://krushiraj.github.io</link><generator>GatsbyJS</generator><lastBuildDate>Mon, 30 Sep 2019 16:48:39 GMT</lastBuildDate><item><title><![CDATA[How I built 'Mini-Terminal']]></title><description><![CDATA[This is an article where I share my experience and the decisions I made while building the  Mini-Terminal . How did it all start? I wantedâ€¦]]></description><link>https://krushiraj.github.io/writings/mini-terminal-story/</link><guid isPermaLink="true">https://krushiraj.github.io/writings/mini-terminal-story/</guid><pubDate>Mon, 22 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote&gt;&lt;p&gt;This is an article where I share my experience and the decisions I made while building the &lt;a href=&quot;https://krushiraj.github.io/mini-terminal&quot;&gt;Mini-Terminal&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;How did it all start?&lt;/h2&gt;&lt;p&gt;I wanted to build a portfolio site for myself. I started looking at various popular portfolios that I found by searching here and there. I decided on how my portfolio would look like and I also had a finalized design for my portfolio in my head. But, I wanted to make something which would be part of my portfolio and which also would showcase my skills in Data Structures, Algorithms and using Front-end frameworks. Prior to this I worked on some proprietary frontend framework by ServiceNow, which was made by picking best of both worlds from React and Vue. I had some prior experience working with React but I never worked with Vue. So I decided to work on Vue for this. My goal was to build a webpage whsich would mock a terminal and file system in a computer. Also, I didnâ€™t want to use any ready made helper libraries or packages to mock the terminal. So I decide to handle the key press events by myself and mock an editor. Only elements that were used in making this webpage were div, span and p.&lt;/p&gt;&lt;h2&gt;The UI building blocks&lt;/h2&gt;&lt;p&gt;First I decided on what components to build. I realised that I should have a container which would handle the key press events. The other components were ReadOnlyText section and EditableText section. So in a CLI based terminal you just have text, which is mostly read only and few parts are editable. This editable text will be converted to ReadOnly once we hit â€˜return/enterâ€™ key to execute the commands we give. So those were the base components on which the whole page was built.&lt;/p&gt;&lt;h2&gt;The internals that give life to UI&lt;/h2&gt;&lt;p&gt;I have implemented a tree with node similar to inode to mock the file-system. I wrote a generic parser and executor components which will parse the text and pass the parsed text as token, which contain some meta data to the executor. The executor will identify the command and execute the function that maps to command. In this way we can have any number of commands and functionalities added with ease in future. Everything was built as generic as possible to extend the capabilities and functionalities with ease. Auto complete suggestions feature was implemented based on the meta data that I had in an object. This is where I have mappings to command names, functions, help text and meta related to arguments and options. This helped me to implement the help command and built a Trie for autocompletion feature.&lt;/p&gt;&lt;h2&gt;Summing up&lt;/h2&gt;&lt;p&gt;That was a great experience for me building this because it required me to put in more than one skill to build whole webpage. My thought to showcase my proficiency in different skills was perfectly potrayed with this webpage because it  required skills like implementation of different and complex data structures, writing algorithms which are efficient and optimal, understanding how Vue components work and communication between the components in the DOM heirarchy, exploring things in JS and CSS.&lt;/p&gt;&lt;p&gt;So, thatâ€™s how the Mini Terminal was built and the story behind it.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My First Project]]></title><description><![CDATA[There is the  fetch  API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to makeâ€¦]]></description><link>https://krushiraj.github.io/writings/project-one/</link><guid isPermaLink="true">https://krushiraj.github.io/writings/project-one/</guid><pubDate>Mon, 22 Apr 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;There is the &lt;code&gt;fetch&lt;/code&gt; API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to make REST calls, get HTML content of a webpage(if we are using node for scraping) and many more things.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;This article is valid for any function that returns a promise.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;An example of such call goes like this&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;fetch(&amp;quot;/url&amp;quot;)
  .then(res =&amp;gt; res.json())
  .then(data =&amp;gt; console.log(data))
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;The Async way&lt;/h2&gt;&lt;p&gt;We could do the same thing, using async and await.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const result = await fetch(&amp;quot;/url&amp;quot;)
const data = await result.json()

console.log(data)

// Or, a one-liner
// const data = await (await fetch(&amp;#x27;/url&amp;#x27;)).json(); ðŸ˜‰
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;I have so many things to fetch!&lt;/h2&gt;&lt;p&gt;Okay fine. We can do that over a classic for loop. The synchronous nature will be preserved. I mean, we can fetch one after the other, synchronously.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
for(const url of urls) {
    const result = await fetch(url);
    const data = await result.json();

    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But what if, the order does not matter? We can fetch them all at once. Yes, all at once, using the Promise API. After all, &lt;code&gt;fetch&lt;/code&gt; returns a promise and thatâ€™s why we &lt;code&gt;await&lt;/code&gt; for it to be resolved.&lt;/p&gt;&lt;p&gt;Promise API has this method &lt;code&gt;Promise.all()&lt;/code&gt; , which can be awaited on for all the promises that it accepts as an argument to be resolved.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
const promises = urls.map(url =&amp;gt; fetch(url));

await Promise.all(promises);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will save us a lot of time. Imagine we want to parse many webpages, around 100, and each webpage takes 2 seconds to be fetched and scraped for information we need. If we fetch it one after the other, it will take us around 200 seconds, which is over 3 minutes. But if we fetch all at once, it will take under a minute.&lt;/p&gt;&lt;h1&gt;Like, really SO MANY!&lt;/h1&gt;&lt;p&gt;What is we have over 10000 urls to fetch. If we do the same thing as above, we will most probably not make it. We will have to face some weird socket hangup error. What can we do about it?&lt;/p&gt;&lt;p&gt;There is a node package called &lt;code&gt;Bluebird&lt;/code&gt; which has its own Promise API and it functions the same. It has this method called &lt;code&gt;map&lt;/code&gt;, which takes an extra options argument where we can set concurrency.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Promise.map(urls =&amp;gt; fetch(url), { concurrency: 100 });&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will, as we can infer from the line, concurrently fetch 100 requests at a time. This will save a significant load on CPU.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const Promise = require(&amp;#x27;bluebird&amp;#x27;).Promise;
const urls = [...];
const promises = await Promise.map(
    urls =&amp;gt; fetch(url),
    { concurrency: 100 }
);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thanks for making it till the end.&lt;/p&gt;&lt;p&gt;Keep on Hacking! âœŒ&lt;/p&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-dnt=&quot;true&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Teslaâ€™s mission is to accelerate the worldâ€™s transition to sustainable energy. &lt;br/&gt;&lt;br/&gt;ðŸŒžâš¡ðŸš—ðŸ”‹ &lt;br/&gt;&lt;br/&gt;(a thread)&lt;/p&gt;â€” Tesla (@Tesla) &lt;a href=&quot;https://twitter.com/Tesla/status/1126575043281080323&quot;&gt;May 9, 2019&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My First Post]]></title><description><![CDATA[There is the  fetch  API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to makeâ€¦]]></description><link>https://krushiraj.github.io/writings/first-post/</link><guid isPermaLink="true">https://krushiraj.github.io/writings/first-post/</guid><pubDate>Sun, 21 Apr 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;There is the &lt;code&gt;fetch&lt;/code&gt; API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to make REST calls, get HTML content of a webpage(if we are using node for scraping) and many more things.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;This article is valid for any function that returns a promise.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;An example of such call goes like this&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;fetch(&amp;quot;/url&amp;quot;)
  .then(res =&amp;gt; res.json())
  .then(data =&amp;gt; console.log(data))
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;The Async way&lt;/h2&gt;&lt;p&gt;We could do the same thing, using async and await.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const result = await fetch(&amp;quot;/url&amp;quot;)
const data = await result.json()

console.log(data)

// Or, a one-liner
// const data = await (await fetch(&amp;#x27;/url&amp;#x27;)).json(); ðŸ˜‰
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;I have so many things to fetch!&lt;/h2&gt;&lt;p&gt;Okay fine. We can do that over a classic for loop. The synchronous nature will be preserved. I mean, we can fetch one after the other, synchronously.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
for(const url of urls) {
    const result = await fetch(url);
    const data = await result.json();

    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But what if, the order does not matter? We can fetch them all at once. Yes, all at once, using the Promise API. After all, &lt;code&gt;fetch&lt;/code&gt; returns a promise and thatâ€™s why we &lt;code&gt;await&lt;/code&gt; for it to be resolved.&lt;/p&gt;&lt;p&gt;Promise API has this method &lt;code&gt;Promise.all()&lt;/code&gt; , which can be awaited on for all the promises that it accepts as an argument to be resolved.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
const promises = urls.map(url =&amp;gt; fetch(url));

await Promise.all(promises);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will save us a lot of time. Imagine we want to parse many webpages, around 100, and each webpage takes 2 seconds to be fetched and scraped for information we need. If we fetch it one after the other, it will take us around 200 seconds, which is over 3 minutes. But if we fetch all at once, it will take under a minute.&lt;/p&gt;&lt;h1&gt;Like, really SO MANY!&lt;/h1&gt;&lt;p&gt;What is we have over 10000 urls to fetch. If we do the same thing as above, we will most probably not make it. We will have to face some weird socket hangup error. What can we do about it?&lt;/p&gt;&lt;p&gt;There is a node package called &lt;code&gt;Bluebird&lt;/code&gt; which has its own Promise API and it functions the same. It has this method called &lt;code&gt;map&lt;/code&gt;, which takes an extra options argument where we can set concurrency.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Promise.map(urls =&amp;gt; fetch(url), { concurrency: 100 });&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will, as we can infer from the line, concurrently fetch 100 requests at a time. This will save a significant load on CPU.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const Promise = require(&amp;#x27;bluebird&amp;#x27;).Promise;
const urls = [...];
const promises = await Promise.map(
    urls =&amp;gt; fetch(url),
    { concurrency: 100 }
);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thanks for making it till the end.&lt;/p&gt;&lt;p&gt;Keep on Hacking! âœŒ&lt;/p&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-dnt=&quot;true&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Teslaâ€™s mission is to accelerate the worldâ€™s transition to sustainable energy. &lt;br/&gt;&lt;br/&gt;ðŸŒžâš¡ðŸš—ðŸ”‹ &lt;br/&gt;&lt;br/&gt;(a thread)&lt;/p&gt;â€” Tesla (@Tesla) &lt;a href=&quot;https://twitter.com/Tesla/status/1126575043281080323&quot;&gt;May 9, 2019&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My First Post]]></title><description><![CDATA[There is the  fetch  API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to makeâ€¦]]></description><link>https://krushiraj.github.io/writings/3rd-post/</link><guid isPermaLink="true">https://krushiraj.github.io/writings/3rd-post/</guid><pubDate>Sun, 21 Apr 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;There is the &lt;code&gt;fetch&lt;/code&gt; API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to make REST calls, get HTML content of a webpage(if we are using node for scraping) and many more things.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;This article is valid for any function that returns a promise.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;An example of such call goes like this&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;fetch(&amp;quot;/url&amp;quot;)
  .then(res =&amp;gt; res.json())
  .then(data =&amp;gt; console.log(data))
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;The Async way&lt;/h2&gt;&lt;p&gt;We could do the same thing, using async and await.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const result = await fetch(&amp;quot;/url&amp;quot;)
const data = await result.json()

console.log(data)

// Or, a one-liner
// const data = await (await fetch(&amp;#x27;/url&amp;#x27;)).json(); ðŸ˜‰
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;I have so many things to fetch!&lt;/h2&gt;&lt;p&gt;Okay fine. We can do that over a classic for loop. The synchronous nature will be preserved. I mean, we can fetch one after the other, synchronously.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
for(const url of urls) {
    const result = await fetch(url);
    const data = await result.json();

    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But what if, the order does not matter? We can fetch them all at once. Yes, all at once, using the Promise API. After all, &lt;code&gt;fetch&lt;/code&gt; returns a promise and thatâ€™s why we &lt;code&gt;await&lt;/code&gt; for it to be resolved.&lt;/p&gt;&lt;p&gt;Promise API has this method &lt;code&gt;Promise.all()&lt;/code&gt; , which can be awaited on for all the promises that it accepts as an argument to be resolved.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
const promises = urls.map(url =&amp;gt; fetch(url));

await Promise.all(promises);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will save us a lot of time. Imagine we want to parse many webpages, around 100, and each webpage takes 2 seconds to be fetched and scraped for information we need. If we fetch it one after the other, it will take us around 200 seconds, which is over 3 minutes. But if we fetch all at once, it will take under a minute.&lt;/p&gt;&lt;h1&gt;Like, really SO MANY!&lt;/h1&gt;&lt;p&gt;What is we have over 10000 urls to fetch. If we do the same thing as above, we will most probably not make it. We will have to face some weird socket hangup error. What can we do about it?&lt;/p&gt;&lt;p&gt;There is a node package called &lt;code&gt;Bluebird&lt;/code&gt; which has its own Promise API and it functions the same. It has this method called &lt;code&gt;map&lt;/code&gt;, which takes an extra options argument where we can set concurrency.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Promise.map(urls =&amp;gt; fetch(url), { concurrency: 100 });&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will, as we can infer from the line, concurrently fetch 100 requests at a time. This will save a significant load on CPU.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const Promise = require(&amp;#x27;bluebird&amp;#x27;).Promise;
const urls = [...];
const promises = await Promise.map(
    urls =&amp;gt; fetch(url),
    { concurrency: 100 }
);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thanks for making it till the end.&lt;/p&gt;&lt;p&gt;Keep on Hacking! âœŒ&lt;/p&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-dnt=&quot;true&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Teslaâ€™s mission is to accelerate the worldâ€™s transition to sustainable energy. &lt;br/&gt;&lt;br/&gt;ðŸŒžâš¡ðŸš—ðŸ”‹ &lt;br/&gt;&lt;br/&gt;(a thread)&lt;/p&gt;â€” Tesla (@Tesla) &lt;a href=&quot;https://twitter.com/Tesla/status/1126575043281080323&quot;&gt;May 9, 2019&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My Second Project]]></title><description><![CDATA[There is the  fetch  API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to makeâ€¦]]></description><link>https://krushiraj.github.io/writings/second-project/</link><guid isPermaLink="true">https://krushiraj.github.io/writings/second-project/</guid><pubDate>Thu, 21 Feb 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;There is the &lt;code&gt;fetch&lt;/code&gt; API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to make REST calls, get HTML content of a webpage(if we are using node for scraping) and many more things.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;This article is valid for any function that returns a promise.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;An example of such call goes like this&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;fetch(&amp;quot;/url&amp;quot;)
  .then(res =&amp;gt; res.json())
  .then(data =&amp;gt; console.log(data))
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;The Async way&lt;/h2&gt;&lt;p&gt;We could do the same thing, using async and await.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const result = await fetch(&amp;quot;/url&amp;quot;)
const data = await result.json()

console.log(data)

// Or, a one-liner
// const data = await (await fetch(&amp;#x27;/url&amp;#x27;)).json(); ðŸ˜‰
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;I have so many things to fetch!&lt;/h2&gt;&lt;p&gt;Okay fine. We can do that over a classic for loop. The synchronous nature will be preserved. I mean, we can fetch one after the other, synchronously.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
for(const url of urls) {
    const result = await fetch(url);
    const data = await result.json();

    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But what if, the order does not matter? We can fetch them all at once. Yes, all at once, using the Promise API. After all, &lt;code&gt;fetch&lt;/code&gt; returns a promise and thatâ€™s why we &lt;code&gt;await&lt;/code&gt; for it to be resolved.&lt;/p&gt;&lt;p&gt;Promise API has this method &lt;code&gt;Promise.all()&lt;/code&gt; , which can be awaited on for all the promises that it accepts as an argument to be resolved.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
const promises = urls.map(url =&amp;gt; fetch(url));

await Promise.all(promises);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will save us a lot of time. Imagine we want to parse many webpages, around 100, and each webpage takes 2 seconds to be fetched and scraped for information we need. If we fetch it one after the other, it will take us around 200 seconds, which is over 3 minutes. But if we fetch all at once, it will take under a minute.&lt;/p&gt;&lt;h1&gt;Like, really SO MANY!&lt;/h1&gt;&lt;p&gt;What is we have over 10000 urls to fetch. If we do the same thing as above, we will most probably not make it. We will have to face some weird socket hangup error. What can we do about it?&lt;/p&gt;&lt;p&gt;There is a node package called &lt;code&gt;Bluebird&lt;/code&gt; which has its own Promise API and it functions the same. It has this method called &lt;code&gt;map&lt;/code&gt;, which takes an extra options argument where we can set concurrency.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Promise.map(urls =&amp;gt; fetch(url), { concurrency: 100 });&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will, as we can infer from the line, concurrently fetch 100 requests at a time. This will save a significant load on CPU.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const Promise = require(&amp;#x27;bluebird&amp;#x27;).Promise;
const urls = [...];
const promises = await Promise.map(
    urls =&amp;gt; fetch(url),
    { concurrency: 100 }
);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thanks for making it till the end.&lt;/p&gt;&lt;p&gt;Keep on Hacking! âœŒ&lt;/p&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-dnt=&quot;true&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Teslaâ€™s mission is to accelerate the worldâ€™s transition to sustainable energy. &lt;br/&gt;&lt;br/&gt;ðŸŒžâš¡ðŸš—ðŸ”‹ &lt;br/&gt;&lt;br/&gt;(a thread)&lt;/p&gt;â€” Tesla (@Tesla) &lt;a href=&quot;https://twitter.com/Tesla/status/1126575043281080323&quot;&gt;May 9, 2019&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[My Final Project]]></title><description><![CDATA[There is the  fetch  API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to makeâ€¦]]></description><link>https://krushiraj.github.io/writings/the-final-one/</link><guid isPermaLink="true">https://krushiraj.github.io/writings/the-final-one/</guid><pubDate>Sat, 21 Apr 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;There is the &lt;code&gt;fetch&lt;/code&gt; API in Node, which allows us to make a HTTP request and get some information from the servers. We can use that to make REST calls, get HTML content of a webpage(if we are using node for scraping) and many more things.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;This article is valid for any function that returns a promise.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;An example of such call goes like this&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;fetch(&amp;quot;/url&amp;quot;)
  .then(res =&amp;gt; res.json())
  .then(data =&amp;gt; console.log(data))
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;The Async way&lt;/h2&gt;&lt;p&gt;We could do the same thing, using async and await.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const result = await fetch(&amp;quot;/url&amp;quot;)
const data = await result.json()

console.log(data)

// Or, a one-liner
// const data = await (await fetch(&amp;#x27;/url&amp;#x27;)).json(); ðŸ˜‰
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;I have so many things to fetch!&lt;/h2&gt;&lt;p&gt;Okay fine. We can do that over a classic for loop. The synchronous nature will be preserved. I mean, we can fetch one after the other, synchronously.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
for(const url of urls) {
    const result = await fetch(url);
    const data = await result.json();

    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But what if, the order does not matter? We can fetch them all at once. Yes, all at once, using the Promise API. After all, &lt;code&gt;fetch&lt;/code&gt; returns a promise and thatâ€™s why we &lt;code&gt;await&lt;/code&gt; for it to be resolved.&lt;/p&gt;&lt;p&gt;Promise API has this method &lt;code&gt;Promise.all()&lt;/code&gt; , which can be awaited on for all the promises that it accepts as an argument to be resolved.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const urls = [...];
const promises = urls.map(url =&amp;gt; fetch(url));

await Promise.all(promises);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will save us a lot of time. Imagine we want to parse many webpages, around 100, and each webpage takes 2 seconds to be fetched and scraped for information we need. If we fetch it one after the other, it will take us around 200 seconds, which is over 3 minutes. But if we fetch all at once, it will take under a minute.&lt;/p&gt;&lt;h1&gt;Like, really SO MANY!&lt;/h1&gt;&lt;p&gt;What is we have over 10000 urls to fetch. If we do the same thing as above, we will most probably not make it. We will have to face some weird socket hangup error. What can we do about it?&lt;/p&gt;&lt;p&gt;There is a node package called &lt;code&gt;Bluebird&lt;/code&gt; which has its own Promise API and it functions the same. It has this method called &lt;code&gt;map&lt;/code&gt;, which takes an extra options argument where we can set concurrency.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Promise.map(urls =&amp;gt; fetch(url), { concurrency: 100 });&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will, as we can infer from the line, concurrently fetch 100 requests at a time. This will save a significant load on CPU.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;const Promise = require(&amp;#x27;bluebird&amp;#x27;).Promise;
const urls = [...];
const promises = await Promise.map(
    urls =&amp;gt; fetch(url),
    { concurrency: 100 }
);

for (const promise of promises) {
    const data = await promise.json();
    console.log(data);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thanks for making it till the end.&lt;/p&gt;&lt;p&gt;Keep on Hacking! âœŒ&lt;/p&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-dnt=&quot;true&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Teslaâ€™s mission is to accelerate the worldâ€™s transition to sustainable energy. &lt;br/&gt;&lt;br/&gt;ðŸŒžâš¡ðŸš—ðŸ”‹ &lt;br/&gt;&lt;br/&gt;(a thread)&lt;/p&gt;â€” Tesla (@Tesla) &lt;a href=&quot;https://twitter.com/Tesla/status/1126575043281080323&quot;&gt;May 9, 2019&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;</content:encoded></item></channel></rss>